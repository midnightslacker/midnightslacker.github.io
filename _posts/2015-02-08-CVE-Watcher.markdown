---
layout: post
title:  "CVE Watcher"
date:   2015-02-08 22:00:00
categories: infosec
---

<a href="https://github.com/midnightslacker"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/e7bbb0521b397edbd5fe43e7f760759336b5e05f/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677265656e5f3030373230302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_green_007200.png"></a>

<h3><b>INTRODUCTION</b></h3>
I wanted to write a quick and dirty program that could track CVEs for a given vendor (e.g. Adobe) or product (e.g. Firefox).
Along with CVE ID, I wanted to track the severity of the vulnerability (CVSS Score) and the date the Vulnerability was published.

To get started, I went to the national vulnerability database (NVD) and did an example search:

`https://web.nvd.nist.gov/view/vuln/search-results?adv_search=true&cves=on`<br>
`&cpe_vendor=cpe%3a%2f%3amicrosoft`<br>
`&pub_date_start_month=0`<br>
`&pub_date_start_year=2015`<br>
`&pub_date_end_month=1`<br>
`&pub_date_end_year=2015`<br>
`&cvss_sev_base=HIGH&cve_id=`

I split the example URL above by the different search terms in the URL. The search terms we care about are vendor, start/end dates and cvss severity. 
Lets get to the code so we can automate these searches!

<h3><b>THE CODE</b></h3>
First, we  import `urllib2` and `beautifulsoup` to grab and parse HTML.
We also import `argparse` to take command line arguments and `re` to use regular expressions to extract data from the raw HTML/Text.

{% highlight python %}
import urllib2
from bs4 import BeautifulSoup
import argparse
import re
{% endhighlight %}

Here are the compiled regular expressions we are going to use to pull out the CVE ID, CVSS Score and Publication Date. 

{% highlight python %}
cve_regex = re.compile("CVE-\d*-\d*\\\\r")
cvss_regex = re.compile("CVSS Severity: \d+.\d HIGH|MEDIUM_HIGH|MEDIUM|LOW")
published_regex = re.compile("Published: \d+\/\d+\/\d+")
{% endhighlight %}

I wrote 'getter' functions for each piece of data we want to extract from the raw HTML response:

{% highlight python %}
def get_cve(content, pattern):
    """
    :rtype : List
    :param content: website text
    :param pattern: regex
    :return: CVE Numbers
    """
    vulnerability = re.findall(pattern, str(content))
    vulnerability = [v.replace('\\r', '') for v in vulnerability]
    return list(vulnerability)


def get_published(content, pattern):
    """
    :rtype : List
    :param content: website text
    :param pattern: regex
    :return: Publish Dates of CVEs
    """
    pubdate = re.findall(pattern, str(content))
    pubdate = [p.replace('Published: ', '') for p in pubdate]
    return list(pubdate)


def get_cvss(content, pattern):
    """
    :rtype : List
    :param content: website text
    :param pattern: regex
    :return: CVSS Score
    """
    score = re.findall(pattern, str(content))
    score = [s.replace('CVSS Severity: ', '') for s in score]
    return list(score)
{% endhighlight %}
You'll also notice there are list comprehensions in each get function. 
These list comprehensions are used to remove parts of each string returned by `re.findall` that I didn't want in the result set. 

The next function is `urlgrab`. This function gets the raw HTML response from the National Vulnerability Database ( with some error/exception handling ) and uses `BeautifulSoup` to parse the HTML and return only the text from the webpage (i.e. no html tags, formatting, etc...).

{% highlight python %}
def urlgrab2(host):
    """
    :rtype : String
    :param host: url
    :param pattern: regex
    :return: Test for web page grab
    """

    try:
        response = urllib2.urlopen(host)
    except urllib2.URLError as e:
        if hasattr(e, 'reason'):
            print "\t [-] Failed to reach " + str(host) + "\n\t [-] Reason: ", e.reason + "\n"
            sys.exit()
        elif hasattr(e, 'code'):
            print "\t [-] The server (%s) couldn't fulfill the requst.\n\t [-] Reason: %s" % (host, e.code)
            sys.exit()

    cve_list = response.readlines()
    soup = BeautifulSoup(str(cve_list))
    text_only = soup.getText().encode("utf-8")
    return text_only
{% endhighlight %}

The last function is the main function. Here we use `argparse` to create command line arguments and a help menu to describe each argument:
{% highlight python %}
def main():
    """
    :return: None
    """

    parser = argparse.ArgumentParser()
    parser.add_argument("-v", "--vendor", help="Name of vendor to search NVD for", type=str)
    parser.add_argument("-p", "--product", help="Specific product made by a vendor \t [OPTIONAL]")
    parser.add_argument("-s", "--start_month", help="Integer value 0 through 11 for start month", type=int)
    parser.add_argument("-S", "--start_year", help="Integer value for start year", type=int)
    parser.add_argument("-e", "--end_month", help="Integer value 0 through 11 for end month", type=int)
    parser.add_argument("-E", "--end_year", help="Integer value for end year", type=int)
    parser.add_argument("-c", "--cvss_score", help="HIGH, MEDIUM_HIGH, MEDIUM, or LOW \t [OPTIONAL]", type=str)

    args = parser.parse_args()
{% endhighlight %}

Next, we use an if/else block to take care of the case if someone wants to search for a specific product or wants all vulnerabilities for a specific vendor:
{% highlight python %}
if args.product is not None:
	url = "https://web.nvd.nist.gov/view/vuln/search-results?adv_search=true&cves=on&cpe_vendor=cpe%3a%2f%{0}" \
              "&cpe_product=cpe%3a%2f%3a%3a{1}" \
              "&pub_date_start_month={2}" \
              "&pub_date_start_year={3}" \
              "&pub_date_end_month={4}" \
              "&pub_date_end_year={5}" \
              "&cvss_sev_base={6}&cve_id=".format(str(args.vendor),
                                                str(args.product),
                                                str(args.start_month),
                                                str(args.start_year),
                                                str(args.end_month),
                                                str(args.end_year),
                                                str(args.cvss_score))
else:
	url = "https://web.nvd.nist.gov/view/vuln/search-results?adv_search=true&cves=on&cpe_vendor=cpe%3a%2f%3a{0}" \
            "&pub_date_start_month={1}" \
            "&pub_date_start_year={2}" \
            "&pub_date_end_month={3}" \
            "&pub_date_end_year={4}" \
            "&cvss_sev_base={5}&cve_id=".format(str(args.vendor),
                                                str(args.start_month),
                                                str(args.start_year),
                                                str(args.end_month),
                                                str(args.end_year),
                                                str(args.cvss_score))
{% endhighlight %}

Lastly, we call our functions we developed previously to get the CVE ID, CVSS Score and Published Date and then we print it to stdout:
{% highlight python %}
    
all_text = urlgrab2(url)
cve_list = get_cve(all_text, cve_regex)
cvss_list = get_cvss(all_text, cvss_regex)
pub_list = get_published(all_text, published_regex)

for element in range(len(cvss_list)):
	print str(args.vendor) + "," + str(cve_list[element]) + "," + str(cvss_list[element]) + "," + str(pub_list[element])

{% endhighlight %}

Here are some examples on how you would run `cveWatcher.py` from the command line:

`python cveWatcher.py -v Adobe -s 0 -S 2015 -e 0 -E 2015 -c MEDIUM_HIGH`<br>
`python cveWatcher.py -v Microsoft -s 0 -S 2015 -e 0 -E 2015 -c HIGH`<br>
`python cveWatcher.py -v Google -p chrome -s 4 -S 2014 -e 11 -E 2014 -c HIGH` 

And here is some example output:

`Adobe,CVE-2014-9161,9.3 HIGH,1/30/2015`<br>
`Adobe,CVE-2015-0312,10.0 HIGH,1/28/2015`<br>
`Adobe,CVE-2015-0311,10.0 HIGH,1/23/2015`<br>
`Adobe,CVE-2015-0310,10.0 HIGH,1/23/2015`<br>
`Adobe,CVE-2015-0309,10.0 HIGH,1/13/2015`<br>
`Adobe,CVE-2015-0308,10.0 HIGH,1/13/2015`

<h3><b>FINAL THOUGHTS</b></h3>
You can write a quick bash script to direct the output to a file and create a .csv file that you can import to other tools or strictly use as a spreadsheet to track vulnerabilities. I'm hoping others find this useful or at the very least a good starting point for similar work. To get the code or fork this project, please click on the "Fork me on Github" banner on the top right of this page and then click on the cveWatcher repo. 
